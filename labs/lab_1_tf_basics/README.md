# Lab 1: TensorFlow Basics
This lab will introduce the basics of writing programs with TensorFlow.

To be honest, this week doesn't involve building anything too exciting.
Combine that with the number of definitions, algorithms, and TensorFlow features we're going to cover, and it might be hard to see why we care about differentiable programming at all.
But this week's concepts are absolutely foundational, and if you get through it you should know basically everything about writing simple programs in TensorFlow.
Stick with it, and I promise it's worth it -- we'll be building cool things soon.

Concepts this week:
 - Tensors (rank, shape, data type) as used in TensorFlow
 - Computational graphs
 - Differentiable programming
 - Gradient descent algorithm

TensorFlow features this week:
 - Overview of API levels
 - Tensors, tensor values, and tensor slices
 - Operations
 - Variables
 - Name scopes
 - Reshapes, transpositions, and reductions
 - Defining a computational graph in the Graph object
 - GradientTape
 - Computing gradients, numerical optimization with Optimizers

Optional material:
 - For a review of all of the relevant basic machine learning material, see the [Deep Learning Book, Chapter 5: Machine Learning Basics](http://www.deeplearningbook.org/contents/ml.html)
 - https://thispersondoesnotexist.com/ is a browser demo of one of the coolest things we can do with machine learning right now: generate realistic pictures of people who don't exist
 - The TensorFlow official low-level guide, [introduction](https://www.tensorflow.org/guide/low_level_intro), and the pages on [tensors](https://www.tensorflow.org/guide/tensors), [variables](https://www.tensorflow.org/guide/variables), and [graphs](https://www.tensorflow.org/guide/graphs)
 - [The Google Developers machine learning crash course on gradient descent](https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent), and the next four pages (through "Playground Exercise")
